{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGzkWh3EAZuT"
      },
      "source": [
        "# YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rib3QvSFAZuX"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2f_o0P8AZuY",
        "outputId": "ea726bbd-b50c-4c0c-a710-779a0e669161"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'weights/yolov8n.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 126MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 /content/Parstech-ai.jpg: 480x640 8 persons, 1 handbag, 1 tie, 44.6ms\n",
            "Speed: 11.0ms preprocess, 44.6ms inference, 1008.7ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO(\"https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt\")\n",
        "results = model(\"/content/Parstech-ai.jpg\")\n",
        "for result in results:\n",
        "    result.save(filename=\"result.jpg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1nfuYG0AZuY"
      },
      "outputs": [],
      "source": [
        "model.export(format=\"onnx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TiMpV6QAZuZ",
        "outputId": "b0996fd8-c676-421d-87b2-641e5bb880a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
            "Loading /content/weights/yolov8n.onnx for ONNX Runtime inference...\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnxruntime-gpu'] not found, attempting AutoUpdate...\n",
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.19.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting coloredlogs (from onnxruntime-gpu)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (24.3.25)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (24.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (3.20.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (1.13.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
            "Downloading onnxruntime_gpu-1.19.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (223.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 223.1/223.1 MB 121.4 MB/s eta 0:00:00\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 191.2 MB/s eta 0:00:00\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 320.9 MB/s eta 0:00:00\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime-gpu\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-gpu-1.19.0\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 11.0s, installed 1 package: ['onnxruntime-gpu']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "image 1/1 /content/Parstech-ai.jpg: 640x640 7 persons, 14.1ms\n",
            "Speed: 2.1ms preprocess, 14.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ],
      "source": [
        "onnx_model = YOLO(\"/content/weights/yolov8n.onnx\")\n",
        "results = onnx_model(\"/content/Parstech-ai.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cc-ieiqzAZuZ"
      },
      "source": [
        "# sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSVl8FAHAZuZ",
        "outputId": "defb4e42-5e31-45b9-d180-0d419f25d6a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: skl2onnx in /usr/local/lib/python3.10/dist-packages (1.17.0)\n",
            "Requirement already satisfied: onnx>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from skl2onnx) (1.16.2)\n",
            "Requirement already satisfied: scikit-learn>=1.1 in /usr/local/lib/python3.10/dist-packages (from skl2onnx) (1.3.2)\n",
            "Requirement already satisfied: onnxconverter-common>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from skl2onnx) (1.14.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.2.1->skl2onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.2.1->skl2onnx) (3.20.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxconverter-common>=1.7.0->skl2onnx) (24.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1->skl2onnx) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1->skl2onnx) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1->skl2onnx) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install skl2onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "XnYmZVRMAZuZ",
        "outputId": "315e38d7-1377-4b08-c908-8c3ee6907baa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(max_iter=300, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(max_iter=300, random_state=1)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "MLPClassifier(max_iter=300, random_state=1)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "iris = load_iris()\n",
        "X,y = iris.data , iris.target\n",
        "X = X.astype(np.float32)\n",
        "X_train , X_test,y_train,y_test = train_test_split(X,y)\n",
        "# model = RandomForestClassifier()\n",
        "model = MLPClassifier(random_state=1, max_iter=300)\n",
        "model.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYS6vhtHAZua",
        "outputId": "6e8454fa-8077-49bb-e9a6-0bc2c9af8f35"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.00019121170043945312"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import onnxruntime as ort\n",
        "import skl2onnx\n",
        "onnx_model = skl2onnx.to_onnx(model, X[0])\n",
        "with open(\"skl2onnxmodel.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())\n",
        "\n",
        "\n",
        "onnx_session = ort.InferenceSession(\n",
        "    \"skl2onnxmodel.onnx\",\n",
        "    providers=[\"CPUExecutionProvider\"]\n",
        ")\n",
        "\n",
        "input_name = onnx_session.get_inputs()[0].name\n",
        "output_name = onnx_session.get_outputs()[0].name\n",
        "start_time = time.time()\n",
        "pred = onnx_session.run([output_name], {input_name: X_test[0]})\n",
        "end_time = time.time()\n",
        "pred\n",
        "end_time - start_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKtHIc30AZua"
      },
      "source": [
        "# torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NQYZT9yAZua",
        "outputId": "c19dbc3c-f199-4343-90b6-d1a61a4828c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: onnx in c:\\users\\nematizadeh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.20 in c:\\users\\nematizadeh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnx) (1.24.3)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\nematizadeh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnx) (4.25.4)\n",
            "Requirement already satisfied: onnxruntime in c:\\users\\nematizadeh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.17.1)\n",
            "Requirement already satisfied: coloredlogs in c:\\users\\nematizadeh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in c:\\users\\nematizadeh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime) (23.5.26)\n",
            "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\nematizadeh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime) (1.24.3)\n",
            "Requirement already satisfied: packaging in c:\\users\\nematizadeh\\appdata\\roaming\\python\\python310\\site-packages (from onnxruntime) (23.1)\n",
            "Requirement already satisfied: protobuf in c:\\users\\nematizadeh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime) (4.25.4)\n",
            "Requirement already satisfied: sympy in c:\\users\\nematizadeh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime) (1.12)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\nematizadeh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\nematizadeh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Requirement already satisfied: pyreadline3 in c:\\users\\nematizadeh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime) (3.4.1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting onnxscript\n",
            "  Downloading onnxscript-0.1.0.dev20240902-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy in c:\\users\\nematizadeh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxscript) (1.24.3)\n",
            "Requirement already satisfied: onnx>=1.16 in c:\\users\\nematizadeh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxscript) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\nematizadeh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxscript) (4.5.0)\n",
            "Collecting ml-dtypes (from onnxscript)\n",
            "  Downloading ml_dtypes-0.4.0-cp310-cp310-win_amd64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: packaging in c:\\users\\nematizadeh\\appdata\\roaming\\python\\python310\\site-packages (from onnxscript) (23.1)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\nematizadeh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnx>=1.16->onnxscript) (4.25.4)\n",
            "Downloading onnxscript-0.1.0.dev20240902-py3-none-any.whl (665 kB)\n",
            "   ---------------------------------------- 0.0/665.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/665.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/665.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/665.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/665.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/665.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/665.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/665.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/665.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/665.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/665.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/665.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/665.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/665.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/665.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/665.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/665.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/665.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/665.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/665.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/665.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/665.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/665.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/665.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/665.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/665.7 kB ? eta -:--:--\n",
            "   --------------- ------------------------ 262.1/665.7 kB ? eta -:--:--\n",
            "   --------------- ------------------------ 262.1/665.7 kB ? eta -:--:--\n",
            "   --------------- ------------------------ 262.1/665.7 kB ? eta -:--:--\n",
            "   --------------- ------------------------ 262.1/665.7 kB ? eta -:--:--\n",
            "   --------------- ------------------------ 262.1/665.7 kB ? eta -:--:--\n",
            "   --------------- ------------------------ 262.1/665.7 kB ? eta -:--:--\n",
            "   --------------- ------------------------ 262.1/665.7 kB ? eta -:--:--\n",
            "   --------------- ------------------------ 262.1/665.7 kB ? eta -:--:--\n",
            "   --------------- ------------------------ 262.1/665.7 kB ? eta -:--:--\n",
            "   --------------- ------------------------ 262.1/665.7 kB ? eta -:--:--\n",
            "   --------------- ------------------------ 262.1/665.7 kB ? eta -:--:--\n",
            "   --------------- ------------------------ 262.1/665.7 kB ? eta -:--:--\n",
            "   --------------- ------------------------ 262.1/665.7 kB ? eta -:--:--\n",
            "   --------------- ------------------------ 262.1/665.7 kB ? eta -:--:--\n",
            "   --------------- ------------------------ 262.1/665.7 kB ? eta -:--:--\n",
            "   --------------- ------------------------ 262.1/665.7 kB ? eta -:--:--\n",
            "   ------------------------------ -------- 524.3/665.7 kB 81.4 kB/s eta 0:00:02\n",
            "   ------------------------------ -------- 524.3/665.7 kB 81.4 kB/s eta 0:00:02\n",
            "   ------------------------------ -------- 524.3/665.7 kB 81.4 kB/s eta 0:00:02\n",
            "   ------------------------------ -------- 524.3/665.7 kB 81.4 kB/s eta 0:00:02\n",
            "   --------------------------------------- 665.7/665.7 kB 97.1 kB/s eta 0:00:00\n",
            "Downloading ml_dtypes-0.4.0-cp310-cp310-win_amd64.whl (126 kB)\n",
            "Installing collected packages: ml-dtypes, onnxscript\n",
            "Successfully installed ml-dtypes-0.4.0 onnxscript-0.1.0.dev20240902\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))': /packages/32/7e/141ad9f3c36ca22acaf1e780ac04630f185a1edc0cb4dec8ce65f724069f/onnxscript-0.1.0.dev20240902-py3-none-any.whl.metadata\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx\n",
        "!pip install onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Vwc4EQ7hAZua"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "bllU5DI5AZub"
      },
      "outputs": [],
      "source": [
        "torch_model = MyModel()\n",
        "torch_input = torch.randn(1, 1, 32, 32)\n",
        "onnx_program = torch.onnx.dynamo_export(torch_model, torch_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9RhTN4quAZub"
      },
      "outputs": [],
      "source": [
        "onnx_program.save(\"my_image_classifier.onnx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0PyBTIS4Ntlv"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "onnx_model= onnx.load(\"my_image_classifier.onnx\")\n",
        "onnx.checker.check_model(onnx_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX22LvhKOFQ0",
        "outputId": "012744c6-3879-4f16-a9b7-02e2f28b4575"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[  -0.031855,   -0.070876,   -0.011677,   -0.052645,    0.063938,   0.0074441,    -0.12582,     0.14289,    0.092258,    0.028948]], dtype=float32)]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import onnxruntime as ort\n",
        "onnx_session = ort.InferenceSession(\n",
        "    \"my_image_classifier.onnx\",\n",
        "    providers=[\"CPUExecutionProvider\"]\n",
        ")\n",
        "input_name = onnx_session.get_inputs()[0].name\n",
        "output_name = onnx_session.get_outputs()[0].name\n",
        "input_name,output_name\n",
        "\n",
        "onnx_input = torch_input.detach().cpu().numpy()\n",
        "pred = onnx_session.run([output_name],{input_name:onnx_input})\n",
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "J82YMkN5upDY"
      },
      "outputs": [],
      "source": [
        "onnxruntime_outputs = pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si72zVHpunx0",
        "outputId": "3832db4a-4a4c-4a06-8816-c805ec2016d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch and ONNX Runtime output matched!\n",
            "Output length: 1\n",
            "Sample output: [array([[  -0.031855,   -0.070876,   -0.011677,   -0.052645,    0.063938,   0.0074441,    -0.12582,     0.14289,    0.092258,    0.028948]], dtype=float32)]\n"
          ]
        }
      ],
      "source": [
        "torch_outputs = torch_model(torch_input)\n",
        "torch_outputs = onnx_program.adapt_torch_outputs_to_onnx(torch_outputs)\n",
        "\n",
        "assert len(torch_outputs) == len(onnxruntime_outputs)\n",
        "for torch_output, onnxruntime_output in zip(torch_outputs, onnxruntime_outputs):\n",
        "    torch.testing.assert_close(torch_output, torch.tensor(onnxruntime_output))\n",
        "\n",
        "print(\"PyTorch and ONNX Runtime output matched!\")\n",
        "print(f\"Output length: {len(onnxruntime_outputs)}\")\n",
        "print(f\"Sample output: {onnxruntime_outputs}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSdb-pGyAZub"
      },
      "source": [
        "# TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUPQOEzPAZub",
        "outputId": "a21bb5ce-77aa-4a40-808b-fa3f7a5d8b8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tf2onnx\n",
            "  Downloading tf2onnx-1.16.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.26.4)\n",
            "Requirement already satisfied: onnx>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.16.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.16.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (24.3.25)\n",
            "Requirement already satisfied: protobuf~=3.20 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (3.20.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2024.7.4)\n",
            "Downloading tf2onnx-1.16.1-py3-none-any.whl (455 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/455.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m450.6/455.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.8/455.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tf2onnx\n",
            "Successfully installed tf2onnx-1.16.1\n"
          ]
        }
      ],
      "source": [
        "!pip install tf2onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "d3ezODzpAZub"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import onnx\n",
        "import onnxruntime as ort\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, decode_predictions\n",
        "import tf2onnx\n",
        "\n",
        "model = ResNet50(weights=\"imagenet\", include_top=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "n8KRL8rFAZub"
      },
      "outputs": [],
      "source": [
        "onnx_model, _ = tf2onnx.convert.from_keras(\n",
        "    model,\n",
        "    [tf.TensorSpec(\n",
        "        model.inputs[0].shape,\n",
        "        dtype=model.inputs[0].dtype,\n",
        "        name=model.inputs[0].name\n",
        "    )]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "dG3iFQsKAZub"
      },
      "outputs": [],
      "source": [
        "onnx.save(onnx_model, \"ResNet50.onnx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "U4IhingFQYJt"
      },
      "outputs": [],
      "source": [
        "onnx_session = ort.InferenceSession(\n",
        "    \"ResNet50.onnx\",\n",
        "    providers=[\"CPUExecutionProvider\"]\n",
        ")\n",
        "\n",
        "input_name = onnx_session.get_inputs()[0].name\n",
        "output_name = onnx_session.get_outputs()[0].name\n",
        "\n",
        "image = Image.open(\"/content/master_groph_11-16_3.jpg\")\n",
        "image = image.resize((224, 224))\n",
        "image = np.array(image).astype(np.float32)\n",
        "image = np.expand_dims(image, axis=0)\n",
        "onnx_input = image\n",
        "pred = onnx_session.run([output_name], {input_name: onnx_input})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeYekOcZ0Ob4",
        "outputId": "bac2aae2-1581-4049-eb66-51c6b6c34ec3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU execution time: 0.2101 seconds\n",
            "GPU execution time: 0.7516 seconds\n"
          ]
        }
      ],
      "source": [
        "image_path = \"/content/master_groph_11-16_3.jpg\"\n",
        "onnx_model_path = \"ResNet50.onnx\"\n",
        "def prepare_image(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    image = image.resize((224, 224))\n",
        "    image = np.array(image).astype(np.float32)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    return image\n",
        "onnx_input = prepare_image(image_path)\n",
        "cpu_start_time = time.time()\n",
        "cpu_session = ort.InferenceSession(onnx_model_path, providers=[\"CPUExecutionProvider\"])\n",
        "input_name = cpu_session.get_inputs()[0].name\n",
        "output_name = cpu_session.get_outputs()[0].name\n",
        "cpu_pred = cpu_session.run([output_name], {input_name: onnx_input})\n",
        "cpu_decoded = decode_predictions(cpu_pred[0], top=5)[0]\n",
        "cpu_end_time = time.time()\n",
        "cpu_execution_time = cpu_end_time - cpu_start_time\n",
        "\n",
        "gpu_start_time = time.time()\n",
        "gpu_session = ort.InferenceSession(onnx_model_path, providers=[\"CUDAExecutionProvider\"])\n",
        "input_name = gpu_session.get_inputs()[0].name\n",
        "output_name = gpu_session.get_outputs()[0].name\n",
        "gpu_pred = gpu_session.run([output_name], {input_name: onnx_input})\n",
        "gpu_decoded = decode_predictions(gpu_pred[0], top=5)[0]\n",
        "gpu_end_time = time.time()\n",
        "gpu_execution_time = gpu_end_time - gpu_start_time\n",
        "\n",
        "print(f\"CPU execution time: {cpu_execution_time:.4f} seconds\")\n",
        "print(f\"GPU execution time: {gpu_execution_time:.4f} seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4HFoAteQwR0",
        "outputId": "d755643d-469f-47f0-d5ce-76c973d784fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[('n02132136', 'brown_bear', 0.7363602),\n",
              "  ('n02447366', 'badger', 0.13681011),\n",
              "  ('n02443114', 'polecat', 0.023592463),\n",
              "  ('n01883070', 'wombat', 0.017849606),\n",
              "  ('n02133161', 'American_black_bear', 0.016436473)]]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decode_predictions(pred[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions: [array([[-4.06648040e-01,  2.29604617e-02,  8.96655843e-02,\n",
            "        -2.68168360e-01,  5.42213678e-01, -6.89561844e-01,\n",
            "        -2.34397903e-01, -1.91860065e-01, -5.31907342e-02,\n",
            "        -1.01466581e-01,  2.74010062e-01, -1.90306172e-01,\n",
            "        -2.95218319e-01, -7.61179850e-02,  1.74073666e-01,\n",
            "        -1.74519300e-01, -3.38219732e-01,  8.24646875e-02,\n",
            "         1.69412941e-01,  1.57940388e-02,  3.13544720e-01,\n",
            "         1.18218325e-02, -7.85402775e-01, -1.64283276e-01,\n",
            "         5.06795049e-01, -2.16232315e-01,  2.65474677e-01,\n",
            "         1.10934399e-01,  3.75916958e-01, -1.95451349e-01,\n",
            "         1.03070915e-01, -2.21609712e-01,  4.34177458e-01,\n",
            "        -1.46528363e-01,  1.40782278e-02, -1.28017336e-01,\n",
            "        -1.04168601e-01,  1.66878700e-02, -9.03395116e-02,\n",
            "        -8.17231759e-02, -4.34298992e-01, -2.51388162e-01,\n",
            "        -1.23273171e-01, -6.64681196e-02, -1.70963123e-01,\n",
            "        -6.57770336e-02, -3.13561022e-01,  2.85186991e-02,\n",
            "        -1.71208009e-03, -1.07352182e-01,  2.36553431e-01,\n",
            "         3.75308275e-01, -5.53140789e-03,  7.10601062e-02,\n",
            "        -2.10047022e-01,  4.98447567e-03,  5.96711040e-01,\n",
            "         5.31511545e-01, -2.26252973e-02,  1.03828236e-01,\n",
            "        -1.42475113e-01, -1.67133629e-01,  5.62154412e-01,\n",
            "         4.92021650e-01,  2.58759677e-01, -1.94806218e-01,\n",
            "         2.94297785e-01, -2.40492225e-01,  1.23994775e-01,\n",
            "        -7.98055977e-02,  2.79442191e-01, -1.08767040e-01,\n",
            "         3.93045545e-01, -2.39955664e-01,  3.70661706e-01,\n",
            "        -2.64766961e-01,  3.71319056e-03, -2.51015246e-01,\n",
            "         3.09650362e-01, -2.07361132e-01, -1.21563777e-01,\n",
            "         3.33340019e-01, -4.71066445e-01,  6.74977377e-02,\n",
            "         6.54147267e-02,  6.89361453e-01,  4.50542212e-01,\n",
            "        -3.80289257e-02,  1.15006000e-01,  3.97737443e-01,\n",
            "         1.09908067e-01, -1.68797612e-01, -3.58957589e-01,\n",
            "         8.92809480e-02, -4.37435359e-01, -3.47278006e-02,\n",
            "         6.14759207e-01, -5.01131058e-01,  3.86843115e-01,\n",
            "        -2.39122018e-01,  6.20099902e-01, -2.42535651e-01,\n",
            "         1.09059855e-01,  1.84112757e-01,  2.75467008e-01,\n",
            "         8.10231388e-01, -3.66534740e-01,  5.12702540e-02,\n",
            "        -1.86260074e-01, -5.47790974e-02, -1.34935692e-01,\n",
            "        -4.83989678e-02,  2.64319688e-01,  8.81542712e-02,\n",
            "        -1.51938245e-01, -2.74211485e-02, -9.43079218e-02,\n",
            "        -2.18653947e-01, -2.53396988e-01,  6.76491618e-01,\n",
            "         6.07311964e-01,  3.40764403e-01,  3.35851163e-01,\n",
            "         4.42516536e-01, -1.98076218e-01, -4.84661341e-01,\n",
            "         2.28269994e-02,  4.09338996e-02,  4.42161739e-01,\n",
            "        -9.77524072e-02,  6.47986710e-01,  3.71288776e-01,\n",
            "         1.32529810e-02, -8.24262798e-02, -5.92528619e-02,\n",
            "         2.79235601e-01, -1.80163369e-01, -2.26741910e-01,\n",
            "        -1.56572700e-01,  2.07524985e-01, -2.88583130e-01,\n",
            "         3.17298234e-01,  1.82673067e-01,  1.17222711e-01,\n",
            "        -5.82692146e-01, -3.26040566e-01, -5.24507523e-01,\n",
            "        -1.73970357e-01, -5.43189824e-01,  5.14401376e-01,\n",
            "        -1.74501777e-01,  1.35121852e-01, -3.65137458e-01,\n",
            "         3.50906312e-01,  8.44581202e-02, -2.44719744e-01,\n",
            "         3.24571729e-01, -6.10470831e-01, -3.13117027e-01,\n",
            "         1.14733234e-01, -3.86054218e-01, -2.53961027e-01,\n",
            "        -6.72607958e-01, -1.31379843e-01, -7.20288083e-02,\n",
            "         6.04738891e-01,  9.30979550e-02,  5.63398637e-02,\n",
            "        -1.65792868e-01,  4.62241888e-01,  1.05270520e-01,\n",
            "         9.58361998e-02, -2.78900504e-01, -4.74495828e-01,\n",
            "        -3.41228068e-01,  6.90603673e-01, -7.31224194e-03,\n",
            "        -7.21543193e-01,  2.74206311e-01,  1.59795210e-01,\n",
            "        -5.52084506e-01, -7.34779462e-02, -4.03173089e-01,\n",
            "         2.23538503e-02,  1.16949536e-01, -9.33240205e-02,\n",
            "        -3.92777652e-01,  4.82938617e-01, -1.21931434e-01,\n",
            "         3.55321057e-02,  1.60626456e-01,  2.77537644e-01,\n",
            "        -1.89175770e-01, -7.03691132e-03, -5.74305415e-01,\n",
            "         1.40276894e-01,  5.14927268e-01, -3.82422119e-01,\n",
            "        -3.99281859e-01,  5.47567964e-01,  5.40708959e-01,\n",
            "         3.67055476e-01,  2.61575393e-02,  2.13957846e-01,\n",
            "        -4.80049372e-01,  1.69338256e-01, -3.77986878e-01,\n",
            "         3.48588228e-02, -7.59884059e-01,  4.66338545e-03,\n",
            "         5.64038992e-01, -3.45819354e-01,  4.13791895e-01,\n",
            "        -7.04813376e-02,  2.76464708e-02, -4.55679297e-01,\n",
            "         4.42880780e-01,  5.49079180e-02,  4.85435277e-02,\n",
            "         5.15216768e-01,  3.13521355e-01, -5.65627694e-01,\n",
            "        -4.49429974e-02,  3.15322757e-01,  2.01560229e-01,\n",
            "         3.65806937e-01,  2.96405196e-01, -7.09609315e-02,\n",
            "        -2.96533823e-01, -4.80732113e-01, -2.59660274e-01,\n",
            "        -4.97406214e-01,  9.79779512e-02,  2.45664805e-01,\n",
            "        -2.17481166e-01, -2.08019406e-01,  1.64010406e-01,\n",
            "        -4.76342201e-01, -1.51112795e-01, -4.93911207e-01,\n",
            "         3.65324974e-01,  6.56554028e-02,  7.85507038e-02,\n",
            "        -3.12213838e-01, -5.09417281e-02, -1.27986073e-02,\n",
            "        -5.11998057e-01, -3.48126978e-01, -1.70349464e-01,\n",
            "        -1.50655746e-01,  1.58448935e-01,  1.66665927e-01,\n",
            "        -8.33025098e-01, -3.55211616e-01, -6.79157674e-02,\n",
            "        -1.61104515e-01,  2.70064235e-01, -4.41298008e-01,\n",
            "        -4.98206317e-01, -6.44569695e-02,  1.63026780e-01,\n",
            "        -2.90315449e-01, -5.12842424e-02,  1.97163075e-01,\n",
            "         1.12911716e-01,  2.68284112e-01, -4.67434749e-02,\n",
            "         3.23472947e-01,  4.61208850e-01, -3.82706463e-01,\n",
            "        -4.54920083e-01, -1.09896079e-01,  2.67590702e-01,\n",
            "        -3.23231101e-01, -5.82792521e-01,  1.81367278e-01,\n",
            "        -1.09661743e-01,  7.01625124e-02, -1.53758436e-01,\n",
            "         1.92761064e-01, -3.78960699e-01, -1.61775500e-01,\n",
            "        -6.14771852e-03,  2.86853939e-01, -5.54432869e-01,\n",
            "        -1.04062699e-01,  2.09392592e-01, -2.84504503e-01,\n",
            "        -4.18734521e-01,  3.56335938e-03,  2.62882590e-01,\n",
            "        -5.60598493e-01, -1.51097670e-01, -6.38686776e-01,\n",
            "         1.51427537e-01, -6.26747161e-02, -7.32452283e-03,\n",
            "        -7.96682462e-02, -1.08849458e-01, -6.32263124e-02,\n",
            "         3.85892421e-01,  7.85724074e-03, -2.13094622e-01,\n",
            "         5.96945733e-03,  2.66442180e-01,  1.89429045e-01,\n",
            "         1.04353152e-01,  5.48667073e-01,  3.64365697e-01,\n",
            "        -2.74554402e-01,  3.53016853e-02,  8.21289346e-02,\n",
            "        -3.45408395e-02, -4.19909917e-02,  6.52012348e-01,\n",
            "         4.25537556e-01,  7.30172470e-02,  1.48624361e-01,\n",
            "         5.57538643e-02,  3.07401985e-01, -1.19163290e-01,\n",
            "         1.83976606e-01,  1.61321953e-01, -2.79162303e-02,\n",
            "         4.64129090e-01, -1.30226687e-01,  3.32507156e-02,\n",
            "         4.17535812e-01, -2.21083075e-01,  7.83031508e-02,\n",
            "        -1.88838795e-01,  6.42683089e-01, -4.81763065e-01,\n",
            "        -2.92046994e-01, -2.07872838e-01,  6.78099692e-04,\n",
            "         1.49585724e-01,  7.18540967e-01,  1.22229710e-01,\n",
            "         5.44483913e-03, -1.48783922e-01,  5.71726441e-01,\n",
            "         4.98629302e-01, -6.75174817e-02,  3.74208003e-01,\n",
            "         2.96141088e-01,  2.05330998e-01,  2.59591013e-01,\n",
            "        -9.64213535e-03,  1.92011595e-01,  7.24539161e-02,\n",
            "        -1.25821047e-02, -5.54673135e-01, -2.49050140e-01,\n",
            "        -4.43488121e-01,  4.82566893e-01,  1.62327915e-01,\n",
            "        -3.61210145e-02, -1.91514462e-01,  8.08078423e-02,\n",
            "        -6.79703131e-02,  1.27067924e-01,  7.37523288e-03,\n",
            "         4.06037688e-01,  2.16974139e-01,  2.42951438e-01,\n",
            "         2.26757601e-01, -4.13526803e-01,  1.73726276e-01,\n",
            "         3.72449726e-01, -1.67750806e-01,  7.37669051e-01,\n",
            "         1.28960609e-01,  1.06163189e-01, -9.45620909e-02,\n",
            "         2.13200450e-01, -2.70312186e-03, -1.33282870e-01,\n",
            "         2.94506520e-01,  1.35270119e-01,  1.95415497e-01,\n",
            "        -2.47075073e-02,  1.86367258e-01,  7.94662237e-02,\n",
            "        -6.50355816e-01,  4.16469611e-02,  2.95794964e-01,\n",
            "        -1.34835869e-01,  7.84140527e-02, -2.34547913e-01,\n",
            "         5.36514819e-02, -1.07205100e-02,  3.29681993e-01,\n",
            "        -4.21751618e-01, -9.77441818e-02, -3.96773756e-01,\n",
            "         8.68663907e-01, -2.15168759e-01, -4.96693552e-02,\n",
            "        -4.24791664e-01,  3.16923589e-01, -2.38912582e-01,\n",
            "        -4.19295907e-01,  1.77420676e-04,  2.90052652e-01,\n",
            "        -1.13648459e-01,  1.19312197e-01, -4.04585004e-02,\n",
            "        -3.62969100e-01, -2.42912054e-01,  1.91898644e-01,\n",
            "         2.29880154e-01,  2.45146811e-01, -2.34091163e-01,\n",
            "         6.32056501e-03, -8.49603340e-02, -2.80484378e-01,\n",
            "         1.77487582e-01, -3.65250371e-03,  1.09924674e-01,\n",
            "         2.00194970e-01, -1.36072397e-01, -6.27705529e-02,\n",
            "         3.73097174e-02, -3.13139915e-01, -1.71305135e-01,\n",
            "        -4.08735685e-02,  6.69282377e-01,  6.49713337e-01,\n",
            "         5.65387607e-02,  1.05298743e-01, -3.63208383e-01,\n",
            "        -3.15301746e-01, -2.90015429e-01, -1.51014999e-01,\n",
            "         3.69092464e-01, -4.64416206e-01,  4.07688618e-01,\n",
            "         2.71016896e-01,  1.43595397e-01,  1.97339714e-01,\n",
            "         1.65028021e-01,  2.23470837e-01,  2.30219364e-01,\n",
            "         3.02979916e-01,  3.84642035e-01,  5.47698438e-02,\n",
            "        -2.59226918e-01,  1.22046739e-01,  7.75544867e-02,\n",
            "        -1.38987705e-01, -5.91108143e-01,  3.33425850e-01,\n",
            "         1.23641178e-01,  2.02509046e-01, -3.51035863e-01,\n",
            "        -1.80080965e-01, -4.83638346e-01, -1.18739545e-01,\n",
            "        -3.07505578e-03,  3.88941377e-01, -4.78543073e-01,\n",
            "         2.15726018e-01, -2.19896406e-01,  2.70623446e-01,\n",
            "        -5.60083449e-01,  5.21209955e-01,  1.40143737e-01,\n",
            "        -1.65434644e-01, -3.58196020e-01,  3.99355799e-01,\n",
            "        -4.87522870e-01,  3.77018154e-02,  3.89768630e-01,\n",
            "        -7.60041416e-01,  5.90756297e-01,  5.97679079e-01,\n",
            "         6.09812081e-01,  2.22736165e-01,  1.24808647e-01,\n",
            "        -1.28527477e-01,  1.09917864e-01,  9.89405662e-02,\n",
            "         1.34529620e-01, -1.11322306e-01, -2.57631600e-01,\n",
            "         1.72816366e-01,  5.39604127e-01,  9.30758566e-02,\n",
            "         1.18381716e-02,  8.41251910e-02,  3.25832143e-02,\n",
            "        -2.19909772e-02, -2.52498060e-01, -4.42586303e-01,\n",
            "        -3.23917061e-01,  1.68878376e-01, -2.70315316e-02,\n",
            "        -3.24861377e-01, -3.75921354e-02,  2.27753893e-01,\n",
            "        -1.19387314e-01, -3.43523175e-02,  4.07341607e-02,\n",
            "        -9.18879807e-02, -4.00289655e-01,  1.21991530e-01,\n",
            "         1.91520862e-02, -3.92377451e-02,  1.81874018e-02,\n",
            "         2.72753090e-01, -4.73080099e-01]], dtype=float32)]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "from PIL import Image\n",
        "\n",
        "model_path = 'model.onnx' \n",
        "onnx_session = ort.InferenceSession(model_path, providers=['CPUExecutionProvider'])\n",
        "\n",
        "input_name = onnx_session.get_inputs()[0].name\n",
        "output_name = onnx_session.get_outputs()[0].name\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = image.resize((112, 112)) \n",
        "    image_np = np.array(image).astype(np.float32)\n",
        "    image_np = np.transpose(image_np, (2, 0, 1))  \n",
        "    image_np = image_np[np.newaxis, :]  \n",
        "    return image_np\n",
        "\n",
        "def run_inference(session, image_path):\n",
        "    image_np = preprocess_image(image_path)\n",
        "    pred = session.run([output_name], {input_name: image_np})\n",
        "    return pred\n",
        "\n",
        "image_path = 'Parstech-ai.jpg' \n",
        "predictions = run_inference(onnx_session, image_path)\n",
        "print(\"Predictions:\", predictions)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
